\section{Related Work}
\label{related_work}
We can categorise haze removal tasks into prior-knowledge and learning-based techniques. The prior-knowledge approaches take advantage of statistical hypotheses. In opposition, learning-based methods learn the nonlinear mapping in the  haze-free and between the given haze-full image. This section, we will embrace the difference between these two techniques in detail. In the prior-based algorithms \cite{prior_cap, prior_filt}, physical assumptions such as atmospheric scattering technique (ATM)   \cite{atm, real_time_atm, atm_illu} and statistical hypotheses are used to expect the outcome to be a haze-free image.
In the prior-based methods \cite{prior1, prior2, prior_cap, prior_cnn1, prior_filt}, authors investigate the factors affecting the image and minimize those factors to get a haze-free outcome. The transmission map with colour attenuation prior is calculated to manipulate the discrepancy between RGB channels. However, these techniques only reach sub-optimal performance in haze removal. Other approaches include polarized filters, multiview images of the common scenery and prior-based hazy methods. He et al. demonstrated dark channels prior (DHCP) \cite{he} to improve visibility in haze-full images. This approach struggles with edge structure and undergoes a halo effect \cite{halo_cai_cnn}. Further approaches Lai et al. \cite{lai} proposed two prior-based transmission maps for the hazy scene, a multi-scale retinex-based algorithm \cite{wang} to estimate luminous detail in the image, colour attenuation prior (CAP) \cite{prior_cap}, and an HSV colourspace method to extract haze-related features. 
\\
In learning-based methods, the first few techniques estimated transmission maps using end-to-end CNN like Cai et al.\cite{halo_cai_cnn} and Ren et al. \cite{ren} Zhang et al. \cite{zhang} suggested an approach to get transmission maps and atmospheric light with atmospheric scattering to estimate haze-free images. A variety of methods used CNN \cite{prior_cnn1, cnn_o, obj_det_cnn, halo_cai_cnn} to get a direct clean haze-free image. The result of the investigation from Chen et al. \cite{gated} using dilated convolutional for haze-free image reconstruction showed better unit performance than the previous existing methods.The approaches like AOD-net \cite{aod} analyzes the contradiction between the  quaint atmospheric models and the haze removal techniques. Later Swami et al. \cite{swami} proposed conditional GAN to remove haze from the degraded hazy images. Now, researchers \cite{res_unp, res_unp1} use an unpaired training approach for a variety of computer vision tasks. Various methods used this unpaired training technique some even used this for motion object segmentation \cite{motion_seg_cnn}. Another application-specific task on haze removal includes Chen et al. \cite{non_uniform} proposed nonuniform remote sensing technique for removing the haze. Zheng et al. \cite{uhd} performed dehazing on a Ultra-high definition image   using multi-guided bilateral learning. Illumination adjustment for haze \cite{col_d_ill}, smoke and fire removal from a single input image. VRHI \cite{VRHI} is used for visibility restoration in hazy images by incorporating haze density model. 
\\
In GAN-based techniques \cite{multi_scale_ad}, BPPnet \cite{bppnet_sota} used a pyramid-based network that gives state-of-the-art results with only 20 pairs of training images. EDN-GTM \cite{sec_sota} use dark channel prior in their approach with a guided transmission map that outperforms the traditional methodology. DW-GAN \cite{dw_gan} used discrete wavelet transform with two-branch GAN. RI-GAN \cite{ri_gan} with residual inception modules in both generator and discriminator. All of the above-mentioned methods works decently on haze removal task, but the GANs are computationally expensive and difficult to implement. Therefore, our model is CNN-based, easy to implement and computationally inexpensive.